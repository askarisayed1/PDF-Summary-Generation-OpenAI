{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e07dfbb",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "__You have been tasked with developing an AI system that can analyze a PDF file and generate a summary. of its contents. Additionally, the system should be integrated with a Chat GPT API to allow users to ask. questions related to the PDF file and received relevant answers__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ee9c7",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "__The objective of this assignment is to develop an AI system that can__:\n",
    "1. Analyze a PDF file and generate a summary of its contents.\n",
    "2. Integrate with a Chat GPT API to answer user questions related to the PDF file.\n",
    "3. Suggest questions based on the PDF file content.\n",
    "4. Provide successive questions based on user questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f20e92",
   "metadata": {},
   "source": [
    "# Requirements:\n",
    "__The following are the requirements for the AI system__:\n",
    "1. The system should be able to analyze a PDF file and generate a summary of its contents using NLP techniques.\n",
    "2. The system should be integrated with a Chat GPT API to allow users to ask questions related to the PDF file and receive relevant answers.\n",
    "3. The system should be able to suggest questions based on the content of the PDF file.\n",
    "4. The system should provide successive questions based on user questions to allow for a more natural conversation flow.\n",
    "5. The system should be able to handle multiple users concurrently.\n",
    "6. The system should be able to handle errors and exceptions gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921a5db",
   "metadata": {},
   "source": [
    "# Steps to Run-:\n",
    "1. __Install the modules__. \n",
    "2. __Replace the openai key on line 3__. \n",
    "3. __Replace the Pdf file path on line 80__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8768e",
   "metadata": {},
   "source": [
    "# Module Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425204cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c23f0e",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627caae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pdfplumber\n",
    "\n",
    "openai.api_key = 'Open_AI_Key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07594c62",
   "metadata": {},
   "source": [
    "# New Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "def generate_summary(text):\n",
    "    prompt = f\"Summarize:\\n\\n{text[:1000]}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=300,\n",
    "        temperature=0.5,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary\n",
    "\n",
    "def generate_questions(prompt, num_questions):\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt + \"\\nQ:\",\n",
    "        max_tokens=200,\n",
    "        temperature=0.5,\n",
    "        n=num_questions,\n",
    "        stop=None\n",
    "    )\n",
    "    questions = [choice.text.strip() for choice in response.choices]\n",
    "    return questions\n",
    "\n",
    "def generate_answer(question, context):\n",
    "    prompt = f\"{context}\\n{question}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=200,\n",
    "        temperature=0.5,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "    answer = response.choices[0].text.strip()\n",
    "    return answer\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    try:\n",
    "        pdf_text = extract_pdf_text(file_path)\n",
    "        summary = generate_summary(pdf_text)\n",
    "        num_initial_questions = 5\n",
    "        initial_questions = generate_questions(summary, num_initial_questions)\n",
    "        \n",
    "        print(f\"\\nSummary for file '{file_path}':\\n{summary}\")\n",
    "        print(\"\\nTop 5 Questions:\")\n",
    "        for i, question in enumerate(initial_questions):\n",
    "            print(f\"{i+1}. {question}\")\n",
    "\n",
    "        # User selects a question\n",
    "        selected_question_index = int(input(\"\\nSelect a question (1-5): \"))\n",
    "        selected_question = initial_questions[selected_question_index - 1]\n",
    "        \n",
    "        # Generate answer based on the selected question\n",
    "        answer = generate_answer(selected_question, summary)\n",
    "        \n",
    "        print(\"\\nUser Selection:\")\n",
    "        print(f\"Question: {selected_question}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "\n",
    "        # Ask user if they want to generate further questions based on the answer\n",
    "        further_questions_input = input(\"\\nDo you want to generate further questions based on the answer? (yes or no): \")\n",
    "        if further_questions_input.lower() == 'yes':\n",
    "            followup_questions = generate_questions(answer, num_initial_questions)\n",
    "            print(\"\\nFollow-up Questions based on the answer:\")\n",
    "            for i, question in enumerate(followup_questions):\n",
    "                print(f\"{i+1}. {question}\")\n",
    "\n",
    "            output = {\n",
    "                'file_path': file_path,\n",
    "                'summary': summary,\n",
    "                'selected_question': selected_question,\n",
    "                'answer': answer,\n",
    "                'followup_questions': followup_questions\n",
    "            }\n",
    "        else:\n",
    "            output = {\n",
    "                'file_path': file_path,\n",
    "                'summary': summary,\n",
    "                'selected_question': selected_question,\n",
    "                'answer': answer\n",
    "            }\n",
    "\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred: {str(e)}\"\n",
    "        return {'file_path': file_path, 'error': error_message}\n",
    "\n",
    "# Specify the paths to the PDF files\n",
    "pdf_paths = ['Analysis Report_ Comparison of Different Models for Dispense Amount Prediction.pdf']\n",
    "\n",
    "# Process the PDF files\n",
    "results = []\n",
    "for pdf_path in pdf_paths:\n",
    "    result = process_pdf(pdf_path)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd22e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
